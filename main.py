import os
import time
from collections import deque
from openai import OpenAI
from langchain.memory import ConversationBufferMemory
from ppt_image_handler import PPTImageHandler
import re
import argparse
from image_search import search_images

# Ki·ªÉm tra bi·∫øn m√¥i tr∆∞·ªùng API Key
GROQ_API_KEY = os.environ.get("GROQ_API_KEY")
CLIENT_AVAILABLE = False

# Kh·ªüi t·∫°o client OpenAI v·ªõi base_url tr·ªè ƒë·∫øn Groq n·∫øu c√≥ API key
if GROQ_API_KEY:
    try:
        client = OpenAI(
            base_url="https://api.groq.com/openai/v1",
            api_key=GROQ_API_KEY
        )
        CLIENT_AVAILABLE = True
    except Exception as e:
        print(f"L·ªói khi t·∫°o client Groq: {e}")
else:
    print("C·∫£nh b√°o: GROQ_API_KEY kh√¥ng ƒë∆∞·ª£c thi·∫øt l·∫≠p. Ch·ª©c nƒÉng chat s·∫Ω kh√¥ng ho·∫°t ƒë·ªông.")

# M√¥ h√¨nh b·∫°n mu·ªën d√πng (Groq h·ªó tr·ª£ Llama 3)
MODEL_NAME = "meta-llama/llama-4-maverick-17b-128e-instruct"  # ho·∫∑c "llama-3.3-70b-versatile"

# C√†i ƒë·∫∑t sliding window cho l·ªãch s·ª≠ h·ªôi tho·∫°i
WINDOW_SIZE = 10
messages = deque(maxlen=WINDOW_SIZE * 2)  # user + assistant messages

# B·ªô nh·ªõ LangChain (n·∫øu b·∫°n c·∫ßn d√πng cho logic kh√°c)
memory = ConversationBufferMemory(return_messages=True)

# Kh·ªüi t·∫°o PowerPoint handler
ppt_handler = PPTImageHandler()

# G·ªçi m√¥ h√¨nh qua OpenAI-compatible API
def get_groq_response(messages):
    if not CLIENT_AVAILABLE:
        return "Chat kh√¥ng kh·∫£ d·ª•ng v√¨ kh√¥ng c√≥ API key ho·∫∑c client b·ªã l·ªói.", 0
    
    try:
        start_time = time.time()
        chat_completion = client.chat.completions.create(
            model=MODEL_NAME,
            messages=messages,
            temperature=0.7
        )
        end_time = time.time()
        response_time = end_time - start_time
        return chat_completion.choices[0].message.content, response_time
    except Exception as e:
        return f"‚ùå L·ªói khi g·ªçi API: {e}", 0

def process_image_command(command):
    """X·ª≠ l√Ω c√°c l·ªánh li√™n quan ƒë·∫øn ·∫£nh"""
    # Pattern 1: t√¨m N ·∫£nh v·ªÅ X
    match = re.match(r"t√¨m (\d+) ·∫£nh v·ªÅ (.+)", command.lower())
    if match:
        num_images = int(match.group(1))
        query = match.group(2)
        result = ppt_handler.process_command({
            "action": "insert_images",
            "query": query,
            "num_images": num_images,
            "mode": "insert"
        })
        return result["message"]
        
    # Pattern 2: ch√®n N ·∫£nh X v√†o slide Y
    match = re.match(r"ch√®n (\d+) ·∫£nh (.+) v√†o slide (\d+)", command.lower())
    if match:
        num_images = int(match.group(1))
        query = match.group(2)
        slide_index = int(match.group(3))
        result = ppt_handler.process_command({
            "action": "insert_images",
            "query": query,
            "num_images": num_images,
            "slide_index": slide_index,
            "mode": "insert"
        })
        return result["message"]
        
    # Pattern 3: t√¨m v√† ch√®n N ·∫£nh X (mode)
    match = re.match(r"t√¨m v√† ch√®n (\d+) ·∫£nh (.+) \((\w+)\)", command.lower())
    if match:
        num_images = int(match.group(1))
        query = match.group(2)
        mode = match.group(3)
        result = ppt_handler.process_command({
            "action": "insert_images",
            "query": query,
            "num_images": num_images,
            "mode": mode
        })
        return result["message"]
    
    return None

# Ch·∫°y v√≤ng l·∫∑p chat
def run_chat():
    global memory, messages
    
    if not CLIENT_AVAILABLE:
        print("üö´ Chat kh√¥ng kh·∫£ d·ª•ng v√¨ kh√¥ng c√≥ API key.")
        return
    
    print("ü§ñ B·∫Øt ƒë·∫ßu chat v·ªõi Groq (OpenAI-compatible) + LangChain (g√µ 'exit' ƒë·ªÉ tho√°t):")
    print("\nC√°c l·ªánh x·ª≠ l√Ω ·∫£nh:")
    print("1. t√¨m N ·∫£nh v·ªÅ X")
    print("2. ch√®n N ·∫£nh X v√†o slide Y")
    print("3. t√¨m v√† ch√®n N ·∫£nh X (insert/crop)")
    
    while True:
        user_input = input("\nüë§ B·∫°n: ").strip()
        if user_input.lower() == "exit":
            print("üëã K·∫øt th√∫c h·ªôi tho·∫°i.")
            import gc
            messages.clear()
            del messages
            del memory
            gc.collect()
            print("üßπ ƒê√£ gi·∫£i ph√≥ng b·ªô nh·ªõ.")
            break

        # Th·ª≠ x·ª≠ l√Ω l·ªánh ·∫£nh tr∆∞·ªõc
        image_response = process_image_command(user_input)
        if image_response:
            print(f"ü§ñ Bot: {image_response}")
            continue

        # N·∫øu kh√¥ng ph·∫£i l·ªánh ·∫£nh, x·ª≠ l√Ω nh∆∞ chat b√¨nh th∆∞·ªùng
        memory.chat_memory.add_user_message(user_input)
        messages.append({"role": "user", "content": user_input})

        bot_reply, response_time = get_groq_response(list(messages))
        print(f"‚è± Th·ªùi gian ph·∫£n h·ªìi: {response_time:.2f} gi√¢y")
        print(f"ü§ñ Bot: {bot_reply}")

        memory.chat_memory.add_ai_message(bot_reply)
        messages.append({"role": "assistant", "content": bot_reply})

def handle_search_command(query: str, num_images: int = 5):
    """X·ª≠ l√Ω l·ªánh t√¨m ki·∫øm ·∫£nh"""
    print(f"üîç ƒêang t√¨m {num_images} ·∫£nh v·ªÅ '{query}'...")
    
    images = search_images(query, per_page=num_images)
    if not images:
        print("‚ùå Kh√¥ng t√¨m th·∫•y ·∫£nh ph√π h·ª£p")
        return
        
    print(f"‚úÖ ƒê√£ t√¨m th·∫•y {len(images)} ·∫£nh:")
    for i, image in enumerate(images, 1):
        print(f"{i}. {image['url']}")

def handle_insert_command(query: str, slide_index: int, num_images: int = 1, mode: str = "insert"):
    """X·ª≠ l√Ω l·ªánh ch√®n ·∫£nh v√†o slide"""
    print(f"üîç ƒêang t√¨m {num_images} ·∫£nh v·ªÅ '{query}'...")
    
    images = search_images(query, per_page=num_images)
    if not images:
        print("‚ùå Kh√¥ng t√¨m th·∫•y ·∫£nh ph√π h·ª£p")
        return
        
    print(f"üìé ƒêang ch√®n {len(images)} ·∫£nh v√†o slide {slide_index}...")
    
    handler = PPTImageHandler()
    for image in images:
        result = handler.process_command({
            "action": "insert_images",
            "image_url": image['url'],
            "slide_index": slide_index,
            "mode": mode
        })
        
        if result["success"]:
            print(f"‚úÖ {result['message']}")
        else:
            print(f"‚ùå {result['error']}")

def main():
    parser = argparse.ArgumentParser(description="PowerPoint Image Assistant")
    subparsers = parser.add_subparsers(dest="command", help="Available commands")
    
    # L·ªánh t√¨m ki·∫øm ·∫£nh
    search_parser = subparsers.add_parser("search", help="T√¨m ki·∫øm ·∫£nh")
    search_parser.add_argument("query", help="T·ª´ kh√≥a t√¨m ki·∫øm")
    search_parser.add_argument("-n", "--num", type=int, default=5, help="S·ªë l∆∞·ª£ng ·∫£nh (m·∫∑c ƒë·ªãnh: 5)")
    
    # L·ªánh ch√®n ·∫£nh
    insert_parser = subparsers.add_parser("insert", help="Ch√®n ·∫£nh v√†o slide")
    insert_parser.add_argument("query", help="T·ª´ kh√≥a t√¨m ki·∫øm")
    insert_parser.add_argument("slide", type=int, help="S·ªë th·ª© t·ª± slide")
    insert_parser.add_argument("-n", "--num", type=int, default=1, help="S·ªë l∆∞·ª£ng ·∫£nh (m·∫∑c ƒë·ªãnh: 1)")
    insert_parser.add_argument("-m", "--mode", choices=["insert", "crop"], default="insert",
                             help="Ch·∫ø ƒë·ªô ch√®n ·∫£nh (m·∫∑c ƒë·ªãnh: insert)")
    
    args = parser.parse_args()
    
    if args.command == "search":
        handle_search_command(args.query, args.num)
    elif args.command == "insert":
        handle_insert_command(args.query, args.slide, args.num, args.mode)
    else:
        parser.print_help()

if __name__ == "__main__":
    main() 